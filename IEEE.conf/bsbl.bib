% This file was created with JabRef 2.9.2.
% Encoding: UTF8

@ARTICLE{Abdulghani2010,
  author = {Amir M. Abdulghani and Alexander J. Casson and Esther Rodriguez-Villegas},
  title = {Compressive Sensing Scalp EEG signals : Implementations and Practical
	Performance},
  journal = {Medical \& Biological Engineering \& Computing},
  year = {2010},
  pages = {1--9},
  file = {Abdulghani2010.pdf:Abdulghani2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.17}
}

@INPROCEEDINGS{aboy2007characterization,
  author = {Aboy, Mateo and Cuesta-Frau, David and Austin, Daniel and Mic{\'o}-Tormos,
	Pau},
  title = {Characterization of sample entropy in the context of biomedical signal
	analysis},
  booktitle = {Engineering in Medicine and Biology Society, 2007. EMBS 2007. 29th
	Annual International Conference of the IEEE},
  year = {2007},
  pages = {5942--5945},
  organization = {IEEE},
  file = {aboy2007characterization.pdf:aboy2007characterization.pdf:PDF}
}

@ARTICLE{acharya2005non,
  author = {Acharya U, Rajendra and Faust, Oliver and Kannathal, N and Chua,
	TjiLeng and Laxminarayan, Swamy},
  title = {Non-linear analysis of EEG signals at various sleep stages},
  journal = {Computer Methods and Programs in Biomedicine},
  year = {2005},
  volume = {80},
  pages = {37--45},
  number = {1},
  file = {acharya2005non.pdf:acharya2005non.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{adali2011complex,
  author = {Adali, T. and Schreier, P.J. and Scharf, L.L.},
  title = {Complex-valued signal processing: the proper way to deal with impropriety},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2011},
  volume = {59},
  pages = {5101--5125},
  number = {11},
  file = {adali2011complex.pdf:adali2011complex.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{akimura2012compressed,
  author = {Akimura, D. and Kawahara, Y. and Asami, T.},
  title = {Compressed sensing method for human activity sensing using mobile
	phone accelerometers},
  booktitle = {Networked Sensing Systems (INSS), 2012 Ninth International Conference
	on},
  year = {2012},
  pages = {1--4},
  organization = {IEEE},
  file = {akimura2012compressed.pdf:akimura2012compressed.pdf:PDF}
}

@ARTICLE{alesanco2010clinical,
  author = {Alesanco, A. and Garc{\'\i}a, J.},
  title = {Clinical assessment of wireless ECG transmission in real-time cardiac
	telemonitoring},
  journal = {Information Technology in Biomedicine, IEEE Transactions on},
  year = {2010},
  volume = {14},
  pages = {1144--1152},
  number = {5},
  file = {alesanco2010clinical.pdf:alesanco2010clinical.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{andra2002vlsi,
  author = {Andra, Kishore and Chakrabarti, Chaitali and Acharya, Tinku},
  title = {A VLSI architecture for lifting-based forward and inverse wavelet
	transform},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2002},
  volume = {50},
  pages = {966--977},
  number = {4},
  publisher = {IEEE}
}

@ARTICLE{andrzejak2001indications,
  author = {Andrzejak, Ralph G and Lehnertz, Klaus and Mormann, Florian and Rieke,
	Christoph and David, Peter and Elger, Christian E},
  title = {Indications of nonlinear deterministic and finite-dimensional structures
	in time series of brain electrical activity: Dependence on recording
	region and brain state},
  journal = {Physical Review E},
  year = {2001},
  volume = {64},
  pages = {061907},
  number = {6},
  file = {andrzejak2001indications.pdf:andrzejak2001indications.pdf:PDF},
  publisher = {APS}
}

@ARTICLE{Babacan2010,
  author = {S. Derin Babacan and Rafael Molina and Aggelos K. Katsaggelos},
  title = {Bayesian Compressive Sensing Using Laplace Priors},
  journal = {IEEE Transactions on Signal Processing},
  year = {2010},
  volume = {19},
  pages = {53--63},
  file = {Babacan2010.pdf:Babacan2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.10}
}

@ARTICLE{Babacan2012,
  author = {S. Derin Babacan and Shinichi Nakajima and Minh N. Do},
  title = {Bayesian Group-Sparse Modeling and Variational Inference},
  journal = {Submitted to IEEE Transactions on Signal Processing},
  year = {2012},
  file = {Babacan2012.pdf:Babacan2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.13}
}

@ARTICLE{Baraniuk2007,
  author = {Baraniuk, R.G.},
  title = {Compressive Sensing [Lecture Notes]},
  journal = {Signal Processing Magazine, IEEE},
  year = {2007},
  volume = {24},
  pages = {118 -121},
  number = {4},
  month = {july },
  abstract = {This lecture note presents a new method to capture and represent compressible
	signals at a rate significantly below the Nyquist rate. This method,
	called compressive sensing, employs nonadaptive linear projections
	that preserve the structure of the signal; the signal is then reconstructed
	from these projections using an optimization process.},
  doi = {10.1109/MSP.2007.4286571},
  file = {Baraniuk2007.pdf:Baraniuk2007.pdf:PDF},
  issn = {1053-5888},
  keywords = {Nyquist rate;compressive sensing;nonadaptive linear projections;optimization
	process;signal capturing;signal reconstruction;signal representation;Nyquist
	criterion;data compression;optimisation;signal reconstruction;signal
	representation;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Baraniuk2010,
  author = {R. G. Baraniuk and V. Cevher and M. F. Duarte and C. Hegde},
  title = {Model-based compressive sensing},
  journal = {IEEE Transactions on Signal Processing},
  year = {2010},
  volume = {56 (4)},
  pages = {1982--2001},
  file = {Baraniuk2010.pdf:Baraniuk2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.10.24}
}

@BOOK{Barshalom2001,
  title = {Estimation with Applications To Tracking and Navigation},
  publisher = {Join Wiley \& Sons, INC.},
  year = {2001},
  author = {Yaakov Bar-Shalom and X.-Rong Li and Thiagalingam Kirubarajan},
  owner = {postgres},
  review = {P23, The Matrix Inversion Lemma},
  timestamp = {2012.06.06}
}

@ARTICLE{becker2011nesta,
  author = {Becker, S. and Bobin, J. and Cand{\`e}s, E.J.},
  title = {NESTA: a fast and accurate first-order method for sparse recovery},
  journal = {SIAM Journal on Imaging Sciences},
  year = {2011},
  volume = {4},
  pages = {1--39},
  number = {1},
  file = {becker2011nesta.pdf:becker2011nesta.pdf:PDF},
  publisher = {SIAM}
}

@ARTICLE{Berg2008,
  author = {Ewout Van Den Berg and Michael P. Friedlander},
  title = {Probing The Pareto Frontier for Basis Pursuit Solutions},
  journal = {SIAM Journal on Scientific Computing},
  year = {2008},
  volume = {31(2)},
  pages = {890--912},
  file = {Berg2008.pdf:Berg2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{berinde2008sparse,
  author = {Berinde, R. and Indyk, P.},
  title = {Sparse recovery using sparse random matrices},
  journal = {preprint},
  year = {2008},
  file = {berinde2008sparse.pdf:berinde2008sparse.pdf:PDF}
}

@BOOK{boyd2004convex,
  title = {Convex optimization},
  publisher = {Cambridge university press},
  year = {2004},
  author = {Boyd, Stephen and Vandenberghe, Lieven}
}

@ARTICLE{Candes2006,
  author = {Candes, E.J. and Romberg, J. and Tao, T.},
  title = {Robust uncertainty principles: exact signal reconstruction from highly
	incomplete frequency information},
  journal = {Information Theory, IEEE Transactions on},
  year = {2006},
  volume = {52},
  pages = { 489 - 509},
  number = {2},
  month = {feb.},
  abstract = {This paper considers the model problem of reconstructing an object
	from incomplete frequency samples. Consider a discrete-time signal
	f isin;C^N and a randomly chosen set of frequencies Omega;. Is it
	possible to reconstruct f from the partial knowledge of its Fourier
	coefficients on the set Omega;? A typical result of this paper is
	as follows. Suppose that f is a superposition of |T| spikes f(t)=
	sigma;_ tau; isin;T f( tau;) delta;(t- tau;) obeying |T| le;C_M middot;(log
	N)^-1 middot; | Omega;| for some constant C_M >0. We do not know
	the locations of the spikes nor their amplitudes. Then with probability
	at least 1-O(N^-M ), f can be reconstructed exactly as the solution
	to the #8467;_1 minimization problem. In short, exact recovery may
	be obtained by solving a convex optimization problem. We give numerical
	values for C_M which depend on the desired probability of success.
	Our result may be interpreted as a novel kind of nonlinear sampling
	theorem. In effect, it says that any signal made out of |T| spikes
	may be recovered by convex programming from almost every set of frequencies
	of size O(|T| middot;logN). Moreover, this is nearly optimal in the
	sense that any method succeeding with probability 1-O(N^-M ) would
	in general require a number of frequency samples at least proportional
	to |T| middot;logN. The methodology extends to a variety of other
	situations and higher dimensions. For example, we show how one can
	reconstruct a piecewise constant (one- or two-dimensional) object
	from incomplete frequency samples - provided that the number of jumps
	(discontinuities) obeys the condition above - by minimizing other
	convex functionals such as the total variation of f.},
  doi = {10.1109/TIT.2005.862083},
  file = {Candes2006.pdf:Candes2006.pdf:PDF},
  issn = {0018-9448},
  keywords = { Fourier coefficient; convex optimization; discrete-time signal; image
	reconstruction; incomplete frequency information; linear programming;
	minimization problem; nonlinear sampling theorem; piecewise constant
	object; probability value; robust uncertainty principle; signal reconstruction;
	sparse random matrix; trigonometric expansion; Fourier analysis;
	convex programming; image reconstruction; image sampling; indeterminancy;
	linear programming; minimisation; piecewise constant techniques;
	probability; signal reconstruction; signal sampling; sparse matrices;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Candes2008a,
  author = {Candes, E.J. and Wakin, M.B.},
  title = {An Introduction To Compressive Sampling},
  journal = {Signal Processing Magazine, IEEE},
  year = {2008},
  volume = {25},
  pages = {21 -30},
  number = {2},
  month = {march },
  abstract = {Conventional approaches to sampling signals or images follow Shannon's
	theorem: the sampling rate must be at least twice the maximum frequency
	present in the signal (Nyquist rate). In the field of data conversion,
	standard analog-to-digital converter (ADC) technology implements
	the usual quantized Shannon representation - the signal is uniformly
	sampled at or above the Nyquist rate. This article surveys the theory
	of compressive sampling, also known as compressed sensing or CS,
	a novel sensing/sampling paradigm that goes against the common wisdom
	in data acquisition. CS theory asserts that one can recover certain
	signals and images from far fewer samples or measurements than traditional
	methods use.},
  doi = {10.1109/MSP.2007.914731},
  file = {Candes2008a.pdf:Candes2008a.pdf:PDF},
  issn = {1053-5888},
  keywords = {Relatively few wavelet;compressed sensing;compressive sampling;data
	acquisition;image recovery;sampling paradigm;sensing paradigm;signal
	recovery;data acquisition;image processing;signal processing equipment;signal
	sampling;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Candes2008,
  author = {Candes, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
  title = {{Enhancing Sparsity by Reweighted l(1) Minimization}},
  journal = {{JOURNAL OF FOURIER ANALYSIS AND APPLICATIONS}},
  year = {{2008}},
  volume = {{14}},
  pages = {{877-905}},
  number = {{5-6}},
  month = {{DEC}},
  note = {{4th IEEE International Symposium on Biomedical Imaging, Arlington,
	VA, APR 12-15, 2007}},
  abstract = {{It is now well understood that (1) it is possible to reconstruct
	sparse signals exactly from what appear to be highly incomplete sets
	of linear measurements and (2) that this can be done by constrained
	l(1) minimization. In this paper, we study a novel method for sparse
	signal recovery that in many situations outperforms l(1) minimization
	in the sense that substantially fewer measurements are needed for
	exact recovery. The algorithm consists of solving a sequence of weighted
	l(1)-minimization problems where the weights used for the next iteration
	are computed from the value of the current solution. We present a
	series of experiments demonstrating the remarkable performance and
	broad applicability of this algorithm in the areas of sparse signal
	recovery, statistical estimation, error correction and image processing.
	Interestingly, superior gains are also achieved when our method is
	applied to recover signals with assumed near-sparsity in overcomplete
	representations-not by reweighting the l(1) norm of the coefficient
	sequence as is common, but by reweighting the l(1) norm of the transformed
	object. An immediate consequence is the possibility of highly efficient
	data acquisition protocols by improving on a technique known as Compressive
	Sensing.}},
  doi = {{10.1007/s00041-008-9045-x}},
  file = {Candes2008.pdf:Candes2008.pdf:PDF},
  issn = {{1069-5869}},
  organization = {{IEEE}},
  owner = {postgres},
  timestamp = {2012.08.18},
  unique-id = {{ISI:000261411300013}}
}

@ARTICLE{chan2008analysis,
  author = {Chan, J.S.K. and Choy, S.T.B.},
  title = {Analysis of Covariance Structures in Time Series},
  journal = {Journal of Data Science},
  year = {2008},
  volume = {6},
  pages = {573--589},
  file = {chan2008analysis.pdf:chan2008analysis.pdf:PDF}
}

@ARTICLE{Chan2008,
  author = {Wai Lam Chan and Matthew L. Moravec and Richard G. Baraniuk and Daniel
	M. Mittleman},
  title = {Terahertz imaging with compressed sensing and phase retrieval},
  journal = {Optics Letters},
  year = {2008},
  volume = {33 (9)},
  pages = {974--976},
  file = {Chan2008.pdf:Chan2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.09}
}

@ARTICLE{Charles2012,
  author = {Adam S. Charles and Christopher J. Rozell},
  title = {Re-Weighted $\ell_1$ Dynamic Filtering for Time-Varying Sparse Signal
	Estimation},
  journal = {IEEE Transactions on Signal Processing (submitted)},
  year = {2012},
  volume = {1},
  pages = {1--20},
  file = {Charles2012.pdf:Charles2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.13}
}

@ARTICLE{chen2012design,
  author = {Chen, F. and Chandrakasan, A.P. and Stojanovic, V.M.},
  title = {Design and analysis of a hardware-efficient compressed sensing architecture
	for data compression in wireless sensors},
  journal = {Solid-State Circuits, IEEE Journal of},
  year = {2012},
  volume = {47},
  pages = {744--756},
  number = {3},
  file = {chen2012design.pdf:chen2012design.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Chen1998,
  author = {S. Chen and D. Donoho and M. Saunders},
  title = {Atomic Decomposition by Basis Pursuit},
  journal = {SIAM Journal on Scientific Computing},
  year = {1998},
  volume = {20(1)},
  pages = {33--61},
  file = {Chen1998.pdf:Chen1998.pdf:PDF},
  owner = {postgres},
  review = {UNREAD, REF ONLY},
  timestamp = {2012.08.14}
}

@ARTICLE{Chen2007,
  author = {Zhe Chen and Andrzej Cichocki},
  title = {Nonnegative Matrix Factorization with Temporal Smoothness and/or
	Spatial Decorrelation Constrains},
  journal = {NIPS},
  year = {2007},
  volume = {1},
  pages = {1--10},
  file = {Chen2007.pdf:Chen2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.11.18}
}

@ARTICLE{davenport2012pros,
  author = {Davenport, Mark A and Laska, Jason N and Treichler, John R and Baraniuk,
	Richard G},
  title = {The Pros and Cons of Compressive Sensing for Wideband Signal Acquisition:
	Noise Folding versus Dynamic Range},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2012},
  volume = {60},
  pages = {4628--4642},
  number = {9},
  publisher = {IEEE}
}

@ARTICLE{dixon2012compressed,
  author = {Dixon, A.M.R. and Allstot, E.G. and Gangopadhyay, D. and Allstot,
	D.J.},
  title = {Compressed Sensing System Considerations for ECG and EMG Wireless
	Biosensors},
  journal = {Biomedical Circuits and Systems, IEEE Transactions on},
  year = {2012},
  volume = {6},
  pages = {156--166},
  number = {2},
  file = {dixon2012compressed.pdf:dixon2012compressed.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{donoho2009observed,
  author = {Donoho, D. and Tanner, J.},
  title = {Observed universality of phase transitions in high-dimensional geometry,
	with implications for modern data analysis and signal processing},
  journal = {Philosophical Transactions of the Royal Society A},
  year = {2009},
  volume = {367},
  pages = {4273--4293},
  number = {1906},
  owner = {postgres},
  timestamp = {2013.02.22}
}

@TECHREPORT{Dow2003,
  author = {Murray Dow},
  title = {Explicit Inverse of Toeplitz and Associated Matrices},
  institution = {Supercomputer Facility, Australian National University},
  year = {2003},
  file = {Dow2003.pdf:Dow2003.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.02.25}
}

@ARTICLE{Du2008,
  author = {Lin Du and Tarik Yardibi and Jian Li and Petre Stoica},
  title = {Review of User Parameter-Free Robust Adaptive Beamforming Algorithms},
  journal = {Asilomar},
  year = {2008},
  volume = {1},
  pages = {363--367},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@ARTICLE{duarte2012signal,
  author = {Duarte, M.F. and Shen, G. and Ortega, A. and Baraniuk, R.G. and Duarte,
	M.F. and Shen, G. and Ortega, A. and Baraniuk, R.G.},
  title = {Signal compression in wireless sensor networks},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical,
	Physical and Engineering Sciences},
  year = {2012},
  volume = {370},
  pages = {118--135},
  number = {1958},
  file = {duarte2012signal.pdf:duarte2012signal.pdf:PDF},
  publisher = {The Royal Society}
}

@ARTICLE{Duarte2008,
  author = {Marco F. Duarte and Mark A. Davenport and Dharmpal Takhar and Jason
	N. Laska and Ting Sun and Kevin F. Kelly and Richard G Baraniuk},
  title = {Single-Pixel Imaging via Compressive Sampling},
  journal = {IEEE Signal Processing Magazine},
  year = {2008},
  volume = {March},
  pages = {83--91},
  file = {Duarte2008.pdf:Duarte2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.13}
}

@ARTICLE{elad2007analysis,
  author = {Elad, M. and Milanfar, P. and Rubinstein, R.},
  title = {Analysis versus synthesis in signal priors},
  journal = {Inverse problems},
  year = {2007},
  volume = {23},
  pages = {947},
  number = {3},
  file = {elad2007analysis.pdf:elad2007analysis.pdf:PDF},
  publisher = {IOP Publishing}
}

@ARTICLE{Eldar2010,
  author = {Y. C. Eldar and P. Kuppinger and H. Bolcskei},
  title = {Block-Sparse signals: uncertainty relations and efficient recovery},
  journal = {IEEE Transaction on Signal Processing},
  year = {2010},
  volume = {58(6)},
  pages = {3042--3054},
  owner = {postgres},
  timestamp = {2013.02.22}
}

@ARTICLE{Faul2002,
  author = {Anita C. Faul and Michael E. Tipping},
  title = {Analysis of Sparse Bayesian Learning},
  journal = {Neural Inform. Process. Syst.},
  year = {2002},
  volume = {14},
  pages = {383--389},
  file = {Faul2002.pdf:Faul2002.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Friedman2010,
  author = {Kerome Friedman and Trevor Hastie and Rob Tibshirani},
  title = {Regularisation Paths for Generalized Linear Models via Coordinate
	Descent},
  journal = {Journal of Statistic Software},
  year = {2010},
  volume = {33(1)},
  pages = {1--22},
  file = {Friedman2010.pdf:Friedman2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ELECTRONIC{Gallager2008,
  author = {Robert G. Gallager},
  month = {January},
  year = {2008},
  title = {Circularly--Symmetric Gaussian random vectors},
  language = {English},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@ARTICLE{goldberger2000physiobank,
  author = {Goldberger, Ary L and Amaral, Luis AN and Glass, Leon and Hausdorff,
	Jeffrey M and Ivanov, Plamen Ch and Mark, Roger G and Mietus, Joseph
	E and Moody, George B and Peng, Chung-Kang and Stanley, H Eugene},
  title = {PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research
	resource for complex physiologic signals},
  journal = {Circulation},
  year = {2000},
  volume = {101},
  pages = {e215--e220},
  number = {23},
  publisher = {Am Heart Assoc}
}

@ARTICLE{Gorodnitsky1997,
  author = {I. F. Gorodnitsky and Bhaskar D. Rao},
  title = {Sparse signal reconstruction from limited data using FOCUSS: a re--weighted
	minimum norm algorithm},
  journal = {IEEE Transactions on Signal Processing},
  year = {1997},
  volume = {45},
  pages = {600--616},
  file = {Gorodnitsky1997.pdf:Gorodnitsky1997.pdf:PDF},
  owner = {postgres},
  review = {UNREAD, REF ONLY},
  timestamp = {2012.08.14}
}

@ARTICLE{haboba2012pragmatic,
  author = {Haboba, J. and Mangia, M. and Pareschi, F. and Rovatti, R. and Setti,
	G.},
  title = {A Pragmatic Look at Some Compressive Sensing Architectures With Saturation
	and Quantization},
  journal = {Emerging and Selected Topics in Circuits and Systems, IEEE Journal
	on},
  year = {2012},
  volume = {2},
  pages = {443--459},
  number = {3},
  file = {haboba2012pragmatic.pdf:haboba2012pragmatic.pdf:PDF},
  publisher = {IEEE}
}

@TECHREPORT{Hale2007,
  author = {Elaine T. Hale and Wotao Yin and Yin Zhang},
  title = {A Fixed-Point Continuation Method for $\ell_1$-Regularized Minimization
	with Applications to Compressed Sensing},
  institution = {CAAM Technical Report TR07-07, Rice University},
  year = {2007},
  file = {Hale2007.pdf:Hale2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Hans2009,
  author = {Chris Hans},
  title = {Bayesian Lasso Regression},
  journal = {Biometrika},
  year = {2009},
  volume = {September},
  pages = {1--11},
  file = {Hans2009.pdf:Hans2009.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{Hennenfent2008,
  author = {Gilles Hennenfent and Ewout van den Berg and Michael P. Friedlander
	and Felix J. Herrmann},
  title = {New insights into one-norm solvers from the Pareto curve},
  journal = {Geophysics},
  year = {2008},
  volume = {73(4)},
  pages = {23--26},
  file = {Hennenfent2008.pdf:Hennenfent2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{Hennenfent2008a,
  author = {Gilles Hennenfent and Felix J. Herrmann},
  title = {One-norm regularized inversion: learning from the Pareto curve},
  year = {2009},
  volume = {April},
  pages = {1--10},
  file = {Hennenfent2008a.pdf:Hennenfent2008a.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{hinton2006fast,
  author = {Hinton, G.E. and Osindero, S. and Teh, Y.W.},
  title = {A fast learning algorithm for deep belief nets},
  journal = {Neural computation},
  year = {2006},
  volume = {18},
  pages = {1527--1554},
  number = {7},
  file = {hinton2006fast.pdf:hinton2006fast.pdf:PDF},
  publisher = {MIT Press}
}

@ARTICLE{Hosseini2012,
  author = {Bamdad Hosseini and Guoqing Liu and Charles Puelz and Samantha Tracht
	and Mikhail Smilovic},
  title = {Visualizing the Pareto Surface},
  journal = {IMA},
  year = {2012},
  pages = {1--20},
  file = {Hosseini2012.pdf:Hosseini2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@TECHREPORT{Hu2010,
  author = {Lei Hu},
  title = {Sparse Bayesian Learning in Complex Domain},
  institution = {NUDT},
  year = {2010},
  file = {Hu2010.pdf:Hu2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.12}
}

@ARTICLE{huang2004flipping,
  author = {Huang, Chao-Tsung and Tseng, Po-Chih and Chen, Liang-Gee},
  title = {Flipping structure: an efficient VLSI architecture for lifting-based
	discrete wavelet transform},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2004},
  volume = {52},
  pages = {1080--1089},
  number = {4},
  publisher = {IEEE}
}

@ARTICLE{huang2006extreme,
  author = {Huang, G.B. and Zhu, Q.Y. and Siew, C.K.},
  title = {Extreme learning machine: theory and applications},
  journal = {Neurocomputing},
  year = {2006},
  volume = {70},
  pages = {489--501},
  number = {1},
  file = {huang2006extreme.pdf:huang2006extreme.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Hunter2004,
  author = {David R. Hunter and Kenneth Lange},
  title = {A Tutorial on MM Algorithms},
  journal = {The American Statistician},
  year = {2004},
  volume = {58(1)},
  pages = {30--37},
  file = {Hunter2004.pdf:Hunter2004.pdf:PDF},
  owner = {postgres},
  review = {注意发掘MM和EM的关系，能说清会描述},
  timestamp = {2012.09.12}
}

@ARTICLE{Hyder2010,
  author = {Md Mashud Hyder and Kaushik Mahata},
  title = {Direction-of-Arrival Estimation Using a Mixed $\ell_{2,0}$ Norm Approximation},
  journal = {IEEE Transactions on Signal Processing},
  year = {2010},
  volume = {58},
  pages = {4646--4655},
  file = {Hyder2010.pdf:Hyder2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@ARTICLE{hyvarinen1999fast,
  author = {Hyvarinen, A.},
  title = {Fast and robust fixed-point algorithms for independent component
	analysis},
  journal = {Neural Networks, IEEE Transactions on},
  year = {1999},
  volume = {10},
  pages = {626--634},
  number = {3},
  owner = {liu benyuan},
  timestamp = {2013.02.05}
}

@ARTICLE{Ji2008,
  author = {Shihao Ji and Ya Xue and Lawrence Carin},
  title = {Bayesian Compressive Sensing},
  journal = {IEEE Transactions on Signal Processing},
  year = {2008},
  volume = {56 (6)},
  pages = {2346--2356},
  file = {Ji2008.pdf:Ji2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.13}
}

@INPROCEEDINGS{Kanevsky2010,
  author = {Kanevsky, D. and Carmi, A. and Horesh, L. and Gurfil, P. and Ramabhadran,
	B. and Sainath, T.N.},
  title = {Kalman filtering for compressed sensing},
  booktitle = {Information Fusion (FUSION), 2010 13th Conference on},
  year = {2010},
  pages = {1 -8},
  month = {july},
  abstract = {Compressed sensing is a new emerging field dealing with the reconstruction
	of a sparse or, more precisely, a compressed representation of a
	signal from a relatively small number of observations, typically
	less than the signal dimension. In our previous work we have shown
	how the Kalman filter can be naturally applied for obtaining an approximate
	Bayesian solution for the compressed sensing problem. The resulting
	algorithm, which was termed CSKF, relies on a pseudo-measurement
	technique for enforcing the sparseness constraint. Our approach raises
	two concerns which are addressed in this paper. The first one refers
	to the validity of our approximation technique. In this regard, we
	provide a rigorous treatment of the CSKF algorithm which is concluded
	with an upper bound on the discrepancy between the exact (in the
	Bayesian sense) and the approximate solutions. The second concern
	refers to the computational overhead associated with the CSKF in
	large scale settings. This problem is alleviated here using an efficient
	measurement update scheme based on Krylov subspace method.},
  file = {Kanevsky2010.pdf:Kanevsky2010.pdf:PDF},
  keywords = {Bayesian solution;CSKF algorithm;Krylov subspace method;compressed
	sensing problem;kalman filtering;measurement update scheme;pseudomeasurement
	technique;signal compressed representation;Bayes methods;Kalman filters;signal
	representation;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Kelly2008,
  author = {Kevin T. Kelly},
  title = {Ockham's Razor, Hume's Problem, Ellsberg's Paradox, Dilation, and
	Optimal Truth Conduciveness},
  year = {2008},
  file = {Kelly2008.pdf:Kelly2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Kim2007,
  author = {Seung-Jean Kim and K. Koh and M. Lustig and Stephen Boyd and Dimitry
	Gorinevsky},
  title = {An Interior-Point Method for Large-Scale $\ell_1$-Regularized Least
	Squares},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year = {2007},
  volume = {1},
  pages = {606--617},
  file = {Kim2007.pdf:Kim2007.pdf:PDF},
  owner = {postgres},
  review = {UNREAD, REF ONLY},
  timestamp = {2012.06.08}
}

@CONFERENCE{Kolter2010,
  author = {J. Zico Kolter and Siddarth Batra and Andrew Y. Ng},
  title = {Energy Disaggregation via Discriminative Sparse Coding},
  booktitle = {NIPS2010},
  year = {2010},
  file = {Kolter2010.pdf:Kolter2010.pdf:PDF},
  owner = {liu benyuan},
  timestamp = {2013.03.30}
}

@TECHREPORT{Lange2007,
  author = {Kenneth Lange},
  title = {The MM Algorithm},
  institution = {Departments of Biomathematics, Hunman Genetics, and Statistics},
  year = {2007},
  file = {Lange2007.pdf:Lange2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.12}
}

@ARTICLE{laska2011democracy,
  author = {Laska, J.N. and Boufounos, P.T. and Davenport, M.A. and Baraniuk,
	R.G.},
  title = {Democracy in action: Quantization, saturation, and compressive sensing},
  journal = {Applied and Computational Harmonic Analysis},
  year = {2011},
  volume = {31},
  pages = {429--443},
  number = {3},
  file = {laska2011democracy.pdf:laska2011democracy.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{laska2011trust,
  author = {Laska, Jason N and Wen, Zaiwen and Yin, Wotao and Baraniuk, Richard
	G},
  title = {Trust, but verify: Fast and accurate signal recovery from 1-bit compressive
	measurements},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2011},
  volume = {59},
  pages = {5289--5301},
  number = {11},
  publisher = {IEEE}
}

@ARTICLE{leistedt2007characterization,
  author = {Leistedt, Samuel and Dumont, Martine and Lanquart, J-P and Jurysta,
	Fabrice and Linkowski, Paul},
  title = {Characterization of the sleep EEG in acutely depressed men using
	detrended fluctuation analysis},
  journal = {Clinical neurophysiology},
  year = {2007},
  volume = {118},
  pages = {940--950},
  number = {4},
  file = {leistedt2007characterization.pdf:leistedt2007characterization.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Lewicki2000,
  author = {Michael Lewicki and Terrence J. Sejnowski},
  title = {Learning Overcomplete Representations},
  journal = {Neural Computation},
  year = {2000},
  volume = {12},
  pages = {337--365},
  file = {Lewicki2000.pdf:Lewicki2000.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{lin2012covariance,
  author = {Lin, L. and Higham, N.J. and Pan, J.},
  title = {Covariance Structure Regularization via Entropy Loss Function},
  year = {2012},
  file = {lin2012covariance.pdf:lin2012covariance.pdf:PDF}
}

@INPROCEEDINGS{liu2012efficient,
  author = {Liu, Jingbo and Jin, Jian and Gu, Yuantao},
  title = {Efficient recovery of block sparse signals via zero-point attracting
	projection},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International
	Conference on},
  year = {2012},
  pages = {3333--3336},
  organization = {IEEE},
  file = {liu2012efficient.pdf:liu2012efficient.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.15}
}

@ARTICLE{MacKay1992,
  author = {David J. C. MacKay},
  title = {Bayesian Interpolation},
  journal = {Neural Computation},
  year = {1992},
  volume = {4(3)},
  pages = {415--447},
  file = {MacKay1992.pdf:MacKay1992.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@BOOK{Mahler2007,
  title = {Statistical Multisource-Multitarget Information Fusion},
  publisher = {Artech House},
  year = {2007},
  author = {Ronald P. S. Mahler},
  file = {Mahler2007.pdf:Mahler2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.06}
}

@ARTICLE{Malioutov2005,
  author = {Dmitry Malioutov and Mujdat Cetin and Alan S. Willsky},
  title = {A Sparse Signal Reconstruction Perspective for Source Localization
	With Sensor Arrays},
  journal = {IEEE Transactions on Signal Processing},
  year = {2005},
  volume = {53},
  pages = {3010--3022},
  file = {Malioutov2005.pdf:Malioutov2005.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@ARTICLE{mamaghanian2011compressed,
  author = {Mamaghanian, H. and Khaled, N. and Atienza, D. and Vandergheynst,
	P.},
  title = {Compressed sensing for real-time energy-efficient {ECG} compression
	on wireless body sensor nodes},
  journal = {Biomedical Engineering, IEEE Transactions on},
  year = {2011},
  volume = {58},
  pages = {2456--2466},
  number = {9},
  file = {mamaghanian2011compressed.pdf:mamaghanian2011compressed.pdf:PDF},
  owner = {liu benyuan},
  publisher = {IEEE},
  timestamp = {2013.01.21}
}

@ARTICLE{Mohamed2012,
  author = {Shakir Mohamed and Katherine A. Heller and Zoubin Ghahramani},
  title = {Bayesian and $L_1$ Approaches for Sparse Unsupervised Learning},
  journal = {ICML2012},
  year = {2012},
  volume = {1},
  pages = {1--8},
  file = {Mohamed2012.pdf:Mohamed2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{Mohimani2008,
  author = {G. Hosein Mohimani and Moassoud Babaie-Zadeh and Christian Jutten},
  title = {A fast approach for overcomplete sparse decomposition based on smoothed
	$\ell^0$ norm},
  journal = {IEEE Transactions on Signal Processing},
  year = {2008},
  volume = {57 (1)},
  pages = {1--13},
  file = {Mohimani2008.pdf:Mohimani2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.10}
}

@CONFERENCE{Mohimani2008a,
  author = {G. H. Mohimani and M. Babaie-Zadeh and C. Jutten},
  title = {Complex-Valued Sparse Representation Based on Smoothed $\ell^0$ Norm},
  booktitle = {ICASSP},
  year = {2008},
  file = {Mohimani2008a.pdf:Mohimani2008a.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.12}
}

@ARTICLE{Moravec2007,
  author = {Matthew L. Moravec and Justin K. Romberg and Richard G. Baraniuk},
  title = {Compressed Sensing Phase Retrieval},
  year = {2007},
  pages = {1--12},
  file = {Moravec2007.pdf:Moravec2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.09}
}

@ARTICLE{Mutshinda2010,
  author = {Crispin M. Mutshinda and Mikko J. Sillanpaa},
  title = {Extended Bayesian Lasso for Multiple Quantitative Trait Loci Mapping
	and Unobserved Phenotype Prediction},
  journal = {Genetics Society of America},
  year = {2010},
  volume = {1},
  pages = {1--9},
  file = {Mutshinda2010.pdf:Mutshinda2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{ning2011geometric,
  author = {Ning, L. and Jiang, X. and Georgiou, T.},
  title = {Geometric methods for estimation of structured covariances},
  journal = {arXiv preprint arXiv:1110.3695},
  year = {2011},
  file = {ning2011geometric.pdf:ning2011geometric.pdf:PDF}
}

@ARTICLE{Park2008,
  author = {Trevor Park and George Casella},
  title = {The Bayesian Lasso},
  year = {2008},
  volume = {1},
  pages = {1--17},
  file = {Park2008.pdf:Park2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ELECTRONIC{Petersen2008,
  author = {Kaare Brandt Petersen and Michael Syskind Pedersen},
  month = {Nov},
  year = {2008},
  title = {The Matrix Cookbook},
  language = {English},
  url = {http://matrixcookbook.com},
  file = {Petersen2008.pdf:Petersen2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.06}
}

@CONFERENCE{Peyre2010,
  author = {Gabriel Peyre and Jalal Fadili},
  title = {Learning Analysis Sparsity Priors},
  year = {2010},
  file = {Peyre2010.pdf:Peyre2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.02.25}
}

@CONFERENCE{Peyre2010a,
  author = {Gabriel Peyre and Jalal Fadili},
  title = {Learning Analysis Sparsity Priors},
  year = {2010},
  file = {Peyre2010.pdf:Peyre2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.02.25}
}

@ARTICLE{Popescu2010,
  author = {D. Popescu and A. Hellicar},
  title = {Point Spread Function Estimation for a Terahertz Imaging System},
  journal = {EURASIP J. Adv. Signal Process},
  year = {2010},
  owner = {postgres},
  timestamp = {2013.03.12}
}

@ARTICLE{Qian2012,
  author = {Wei Qian and Yuhong Yang},
  title = {Model Selection via Standard error adjusted adaptive lasso},
  journal = {Ann Inst Stat Math},
  year = {2012},
  volume = {1},
  pages = {1--24},
  file = {Qian2012.pdf:Qian2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@INPROCEEDINGS{Qiu2009,
  author = {Chenlu Qiu and Wei Lu and Vaswani, N.},
  title = {Real-time dynamic MR image reconstruction using Kalman Filtered Compressed
	Sensing},
  booktitle = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE
	International Conference on},
  year = {2009},
  pages = {393 -396},
  month = {april},
  abstract = {In recent work, Kalman Filtered Compressed Sensing (KF-CS) was proposed
	to causally reconstruct time sequences of sparse signals, from a
	limited number of ldquoincoherentrdquo measurements. In this work,
	we develop the KF-CS idea for causal reconstruction of medical image
	sequences from MR data. This is the first real application of KF-CS
	and is considerably more difficult than simulation data for a number
	of reasons, for example, the measurement matrix for MR is not as
	ldquoincoherentrdquo and the images are only compressible (not sparse).
	Greatly improved reconstruction results (as compared to CS and its
	recent modifications) on reconstructing cardiac and brain image sequences
	from dynamic MR data are shown.},
  doi = {10.1109/ICASSP.2009.4959603},
  file = {Qiu2009.pdf:Qiu2009.pdf:PDF},
  issn = {1520-6149},
  keywords = {Kalman filtered compressed sensing;MR image reconstruction;medical
	images;sparse signals;Kalman filters;biomedical MRI;image reconstruction;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Qiu2010,
  author = {K. Qiu and A. Dogandzic},
  title = {Variance-component based sparse signal reconstruction and model selection},
  journal = {IEEE Transactions on Signal Processing},
  year = {2010},
  volume = {58(6)},
  pages = {2935--2952},
  file = {Qiu2010.pdf:Qiu2010.pdf:PDF},
  owner = {postgres},
  review = {UNREAD, REF ONLY},
  timestamp = {2012.08.18}
}

@ELECTRONIC{Roweis1999,
  author = {Sam Roweis},
  month = {June},
  year = {1999},
  title = {Matrix Identities},
  language = {English},
  file = {Roweis1999.pdf:Roweis1999.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.06}
}

@ELECTRONIC{Roweis1999a,
  author = {Sam Roweis},
  month = {July},
  year = {1999},
  title = {Gaussian Identities},
  language = {English},
  file = {Roweis1999.pdf:Roweis1999.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.06}
}

@ARTICLE{rubinstein2010dictionaries,
  author = {Rubinstein, Ron and Bruckstein, Alfred M and Elad, Michael},
  title = {Dictionaries for sparse representation modeling},
  journal = {Proceedings of the IEEE},
  year = {2010},
  volume = {98},
  pages = {1045--1057},
  number = {6},
  file = {rubinstein2010dictionaries.pdf:rubinstein2010dictionaries.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{rubinstein2008efficient,
  author = {Rubinstein, Ron and Zibulevsky, Michael and Elad, Michael},
  title = {Efficient implementation of the K-SVD algorithm using batch orthogonal
	matching pursuit},
  journal = {CS Technion},
  year = {2008},
  file = {rubinstein2008efficient.pdf:rubinstein2008efficient.pdf:PDF}
}

@ELECTRONIC{Sameni2012,
  author = {R. Sameni},
  month = {January},
  year = {2012},
  title = {OSET: The Open-Source Electrophysiological toolbox},
  url = {http://www.oset.ir},
  owner = {postgres},
  timestamp = {2013.03.12}
}

@ARTICLE{Seeger2010,
  author = {Matthias W. Seeger and David P. Wipf},
  title = {Variational Bayesian Inference Techniques},
  journal = {IEEE Signal Processing Magazine},
  year = {2010},
  volume = {November},
  pages = {81--91},
  file = {Seeger2010.pdf:Seeger2010.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.17}
}

@PHDTHESIS{Shen2012,
  author = {Hao Shen},
  title = {Compressed Sensing on Terahertz Imaging},
  school = {University of Liverpool},
  year = {2012},
  file = {Shen2012.pdf:Shen2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.13}
}

@ARTICLE{Shimamura2006,
  author = {Teppei Shimamura and Hiroyuki Minami and Masahiro Mizuta},
  title = {Regularization Parameter Selection in the Group Lasso},
  year = {2006},
  pages = {1--7},
  file = {Shimamura2006.pdf:Shimamura2006.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@INPROCEEDINGS{shoeb2010application,
  author = {Shoeb, Ali and Guttag, John},
  title = {Application of machine learning to epileptic seizure detection},
  booktitle = {Proc. of int. conf. on machine learning},
  year = {2010},
  file = {shoeb2010application.pdf:shoeb2010application.pdf:PDF}
}

@PHDTHESIS{shoeb2009application,
  author = {Shoeb, Ali Hossam},
  title = {Application of machine learning to epileptic seizure onset detection
	and treatment},
  school = {Massachusetts Institute of Technology},
  year = {2009},
  file = {shoeb2009application.pdf:shoeb2009application.pdf:PDF}
}

@ARTICLE{Shutin2012,
  author = {Dmitriy Shutin and Sanjeev R. Kulkarni and H. Vincent Poor},
  title = {Incremental Reformulated Automatic Relevance Determination},
  journal = {IEEE Transactions on Signal Processing},
  year = {2012},
  volume = {60(9)},
  pages = {4977--4981},
  file = {Shutin2012.pdf:Shutin2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.13}
}

@ARTICLE{skodras2001jpeg,
  author = {Skodras, Athanassios and Christopoulos, Charilaos and Ebrahimi, Touradj},
  title = {The JPEG 2000 still image compression standard},
  journal = {Signal Processing Magazine, IEEE},
  year = {2001},
  volume = {18},
  pages = {36--58},
  number = {5},
  publisher = {IEEE}
}

@PHDTHESIS{skretting2002sparse,
  author = {Skretting, Karl},
  title = {Sparse signal representation using overlapping frames},
  school = {M{\"a}lardalen University},
  year = {2002},
  __markedentry = {},
  file = {skretting2002sparse.pdf:skretting2002sparse.pdf:PDF}
}

@ARTICLE{song2010new,
  author = {Song, Yuedong and Li{\`o}, Pietro},
  title = {A new approach for epileptic seizure detection: sample entropy based
	feature extraction and extreme learning machine},
  journal = {Journal of Biomedical Science and Engineering},
  year = {2010},
  volume = {3},
  pages = {556--567},
  number = {6},
  file = {song2010new.pdf:song2010new.pdf:PDF},
  publisher = {Scientific Research Publishing}
}

@ELECTRONIC{Tibshirani2011a,
  author = {Robert Tibshirani},
  title = {The Lasso: some novel algorithms and applications},
  file = {Tibshirani2011a.pdf:Tibshirani2011a.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{Tibshirani2011,
  author = {Robert Tibshirani},
  title = {Regression shrinkage and selection via the lasso},
  journal = {J. R. Statist. Soc. B},
  year = {2011},
  volume = {73},
  pages = {273--282},
  file = {Tibshirani2011.pdf:Tibshirani2011.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@CONFERENCE{Tipping2004,
  author = {Michael E. Tipping},
  title = {Bayesian Inference : An Introduction to Principles and Practice in
	Machine Learning},
  booktitle = {Advanced Lectures on Machine Learning},
  year = {2004},
  editor = {O. Bousquet and U. von Luxburg and G. Ratsch},
  pages = {41-62},
  publisher = {Springer},
  file = {Tipping2004.pdf:Tipping2004.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Tipping2001,
  author = {Michael E. Tipping},
  title = {Sparse Bayesian Learning and the Relevance Vector Machine},
  journal = {Journal of Machine Learning Research},
  year = {2001},
  volume = {1},
  pages = {211--244},
  file = {Tipping2001.pdf:Tipping2001.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@CONFERENCE{Tipping2003,
  author = {Michael E. Tipping and Anita C. Faul},
  title = {Fast Marginal Likelihood Maximisation for Sparse Bayesian Models},
  booktitle = {Proceedings of the Ninth International Workshop on Artificial Intelligence
	and Statistics},
  year = {2003},
  editor = {C. M. Bishop and B. J. Frey},
  pages = {3-6},
  address = {Key West, FL},
  file = {Tipping2003.pdf:Tipping2003.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Tropp2005,
  author = {Joel A. Tropp and Anna C. Gilbert and Martin J. Strauss},
  title = {Algorithms for Simultaneous Sparse Approximation Part I: Greedy Pursuit},
  journal = {IEEE Transactions on Signal Processing},
  file = {Tropp2005.pdf:Tropp2005.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Tropp2005a,
  author = {Joel A. Tropp and Anna C. Gilbert and Martin J. Strauss},
  title = {Algorithms for Simultaneous Sparse Approximation Part II: Convex
	Relaxation},
  journal = {IEEE Transactions on Signal Processing},
  file = {Tropp2005a.pdf:Tropp2005a.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Tzikas2008,
  author = {Dimitris G. Tzikas and Aristidis C. Likas and Nikolaos P. Galatsanos},
  title = {The Variational Approximation for Bayesian Inference},
  journal = {IEEE Signal Processing Magazine},
  year = {2008},
  volume = {November},
  pages = {131--146},
  file = {Tzikas2008.pdf:Tzikas2008.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.17}
}

@ARTICLE{van2008probing,
  author = {Van Den Berg, E. and Friedlander, M.P.},
  title = {Probing the Pareto frontier for basis pursuit solutions},
  journal = {SIAM Journal on Scientific Computing},
  year = {2008},
  volume = {31},
  pages = {890--912},
  number = {2},
  owner = {postgres},
  timestamp = {2013.02.22}
}

@INPROCEEDINGS{Vaswani2009,
  author = {Vaswani, N.},
  title = {Analyzing Least Squares and Kalman Filtered Compressed Sensing},
  booktitle = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE
	International Conference on},
  year = {2009},
  pages = {3013 -3016},
  month = {april},
  abstract = {In recent work, we studied the problem of causally reconstructing
	time sequences of spatially sparse signals, with unknown and slow
	time-varying sparsity patterns, from a limited number of linear ldquoincoherentrdquo
	measurements. We proposed a solution called Kalman filtered compressed
	sensing (KF-CS). The key idea is to run a reduced order KF only for
	the current signal's estimated nonzero coefficients' set, while performing
	CS on the Kalman filtering error to estimate new additions, if any,
	to the set. KF may be replaced by least squares (LS) estimation and
	we call the resulting algorithm LS-CS. In this work, (a) we bound
	the error in performing CS on the LS error and (b) we obtain the
	conditions under which the KF-CS (or LS-CS) estimate converges to
	that of a genie-aided KF (or LS), i.e. the KF (or LS) which knows
	the true nonzero sets.},
  doi = {10.1109/ICASSP.2009.4960258},
  file = {Vaswani2009.pdf:Vaswani2009.pdf:PDF},
  issn = {1520-6149},
  keywords = {Kalman filtered compressed sensing;Kalman filtering error;causal time
	sequence reconstruction;genie-aided KF;least squares estimation;linear
	incoherent measurements;reduced order KF;signal estimated nonzero
	coefficient set;slow time-varying sparsity pattern;spatially sparse
	signals;Kalman filters;data compression;least squares approximations;reduced
	order systems;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@INPROCEEDINGS{Vaswani2008,
  author = {Vaswani, N.},
  title = {Kalman filtered Compressed Sensing},
  booktitle = {Image Processing, 2008. ICIP 2008. 15th IEEE International Conference
	on},
  year = {2008},
  pages = {893 -896},
  month = {oct.},
  abstract = {We consider the problem of reconstructing time sequences of spatially
	sparse signals (with unknown and time-varying sparsity patterns)
	from a limited number of linear "incoherent" measurements, in real-time.
	The signals are sparse in some transform domain referred to as the
	sparsity basis. For a single spatial signal, the solution is provided
	by Compressed Sensing (CS). The question that we address is, for
	a sequence of sparse signals, can we do better than CS, if (a) the
	sparsity pattern of the signal's transform coefficients' vector changes
	slowly over time, and (b) a simple prior model on the temporal dynamics
	of its current non-zero elements is available. The overall idea of
	our solution is to use CS to estimate the support set of the initial
	signal's transform vector. At future times, run a reduced order Kalman
	filter with the currently estimated support and estimate new additions
	to the support set by applying CS to the Kalman innovations or filtering
	error (whenever it is "large").},
  doi = {10.1109/ICIP.2008.4711899},
  file = {Vaswani2008.pdf:Vaswani2008.pdf:PDF},
  issn = {1522-4880},
  keywords = {Kalman filtered compressed sensing;reduced order Kalman filter;signal
	transform vector;sparsity basis;sparsity pattern;spatially sparse
	signals;time sequence reconstruction;transform domain;Kalman filters;least
	mean squares methods;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@INPROCEEDINGS{wan2012sparse,
  author = {Wan, J. and Zhang, Z. and Yan, J. and Li, T. and Rao, B.D. and Fang,
	S. and Kim, S. and Risacher, SL and Saykin, A.J. and Shen, L.},
  title = {Sparse Bayesian multi-task learning for predicting cognitive outcomes
	from neuroimaging measures in Alzheimer's disease},
  booktitle = {Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference
	on},
  year = {2012},
  pages = {940--947},
  organization = {IEEE},
  file = {wan2012sparse.pdf:wan2012sparse.pdf:PDF}
}

@ARTICLE{Wang2009,
  author = {Z. Wang and A. Bovik},
  title = {Mean Squared Error : Love it or leave it ? a new look at signal fidelity
	measures.},
  journal = {IEEE Signal Processing Magazine},
  year = {2009},
  volume = {26 (1)},
  pages = {98--117},
  owner = {postgres},
  timestamp = {2013.03.17}
}

@TECHREPORT{Williams1994,
  author = {Peter M. Williams},
  title = {Bayesian Regularisation and Pruning using a Laplace Prior},
  institution = {School of Cognitive and Computing Sciences, University of Sussex},
  year = {1994},
  type = {Cognitive Science Research Paper, CSRP--312},
  file = {Williams1994.pdf:Williams1994.pdf:PDF},
  owner = {postgres},
  review = {See.
	
	
	对比参见MacKay1990 Beysian 约束的通用形式，然后本文主要工作在于Laplace先验},
  timestamp = {2012.08.18}
}

@CONFERENCE{Wipf2007a,
  author = {David Wipf and Sirkantan Nagarajan},
  title = {A New View of Automatic Relevance Determination},
  booktitle = {The 21 Annu. Conf. Neural Inf. Process. Syst., Vancouver, BC, Canada},
  year = {2007},
  file = {Wipf2007a.pdf:Wipf2007a.pdf:PDF},
  journal = {Neural Inform. Process. Syst.},
  owner = {postgres},
  timestamp = {2012.09.12}
}

@CONFERENCE{Wipf2004a,
  author = {David Wipf and Jason Palmer and Bhaskar D. Rao},
  title = {Perspective on Sparse Bayesian Learning},
  booktitle = {Neural Inf. Process. Syst.},
  year = {2004},
  volume = {16},
  file = {Wipf2004a.pdf:Wipf2004a.pdf:PDF},
  journal = {Neural Inform. Process. Syst.},
  owner = {postgres},
  timestamp = {2012.08.16}
}

@ARTICLE{Wipf2011,
  author = {Wipf, D.P. and Rao, B.D. and Nagarajan, S.},
  title = {Latent Variable Bayesian Models for Promoting Sparsity},
  journal = {Information Theory, IEEE Transactions on},
  year = {2011},
  volume = {57},
  pages = {6236 -6255},
  number = {9},
  month = {sept. },
  abstract = {Many practical methods for finding maximally sparse coefficient expansions
	involve solving a regression problem using a particular class of
	concave penalty functions. From a Bayesian perspective, this process
	is equivalent to maximum a posteriori (MAP) estimation using a sparsity-inducing
	prior distribution (Type I estimation). Using variational techniques,
	this distribution can always be conveniently expressed as a maximization
	over scaled Gaussian distributions modulated by a set of latent variables.
	Alternative Bayesian algorithms, which operate in latent variable
	space leveraging this variational representation, lead to sparse
	estimators reflecting posterior information beyond the mode (Type
	II estimation). Currently, it is unclear how the underlying cost
	functions of Type I and Type II relate, nor what relevant theoretical
	properties exist, especially with regard to Type II. Herein a common
	set of auxiliary functions is used to conveniently express both Type
	I and Type II cost functions in either coefficient or latent variable
	space facilitating direct comparisons. In coefficient space, the
	analysis reveals that Type II is exactly equivalent to performing
	standard MAP estimation using a particular class of dictionary- and
	noise-dependent, nonfactorial coefficient priors. One prior (at least)
	from this class maintains several desirable advantages over all possible
	Type I methods and utilizes a novel, nonconvex approximation to the
	/l/_0 norm with most, and in certain quantifiable conditions all,
	local minima smoothed away. Importantly, the global minimum is always
	left unaltered unlike standard /l/_1 -norm relaxations. This ensures
	that any appropriate descent method is guaranteed to locate the maximally
	sparse solution.},
  doi = {10.1109/TIT.2011.2162174},
  file = {Wipf2011.pdf:Wipf2011.pdf:PDF},
  issn = {0018-9448},
  keywords = {MAP estimation;alternative Bayesian algorithm;auxiliary functions;coefficient
	space;concave penalty function;latent variable Bayesian model;maximization;maximum
	a posteriori estimation;nonconvex approximation;regression problem;scaled
	Gaussian distribution;sparsity-inducing prior distribution;variational
	representation;variational techniques;Gaussian distribution;Regge
	poles;concave programming;estimation theory;information theory;regression
	analysis;sparse matrices;variational techniques;},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@PHDTHESIS{Wipf2006,
  author = {David Paul Wipf},
  title = {Bayesian Methods for Finding Sparse Representations},
  school = {University of California, San Diego},
  year = {2006},
  file = {Wipf2006.pdf:Wipf2006.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.15}
}

@ARTICLE{wipf2010iterative,
  author = {David P. Wipf and Srikantan S. Nagarajan},
  title = {Iterative Reweighted $\ell_1$ and $\ell_2$ Methods for Finding Sparse
	Solutions},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year = {2010},
  volume = {4 (2)},
  pages = {317--329},
  file = {wipf2010iterative.pdf:wipf2010iterative.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.17}
}

@ARTICLE{Wipf2010,
  author = {David P. Wipf and Julia P. Owen and Hagai T. Attias and Kensuke Sekihara
	and Srikantan S. Nagarajan},
  title = {Robust Bayesian estimation of the location, orientation, and time
	course of multiple correlated neural sources using MEG},
  journal = {NeuroImage},
  year = {2010},
  volume = {49},
  pages = {641--655},
  number = {1},
  abstract = {The synchronous brain activity measured via MEG (or EEG) can be interpreted
	as arising from a collection (possibly large) of current dipoles
	or sources located throughout the cortex. Estimating the number,
	location, and time course of these sources remains a challenging
	task, one that is significantly compounded by the effects of source
	correlations and unknown orientations and by the presence of interference
	from spontaneous brain activity, sensor noise, and other artifacts.
	This paper derives an empirical Bayesian method for addressing each
	of these issues in a principled fashion. The resulting algorithm
	guarantees descent of a cost function uniquely designed to handle
	unknown orientations and arbitrary correlations. Robust interference
	suppression is also easily incorporated. In a restricted setting,
	the proposed method is shown to produce theoretically zero reconstruction
	error estimating multiple dipoles even in the presence of strong
	correlations and unknown orientations, unlike a variety of existing
	Bayesian localization methods or common signal processing techniques
	such as beamforming and sLORETA. Empirical results on both simulated
	and real data sets verify the efficacy of this approach.},
  doi = {10.1016/j.neuroimage.2009.06.083},
  file = {Wipf2010.pdf:Wipf2010.pdf:PDF},
  issn = {1053-8119},
  owner = {postgres},
  timestamp = {2012.08.18},
  url = {http://www.sciencedirect.com/science/article/pii/S105381190900696X}
}

@ARTICLE{Wipf2007,
  author = {David P. Wipf and Rao, B.D.},
  title = {An Empirical Bayesian Strategy for Solving the Simultaneous Sparse
	Approximation Problem},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2007},
  volume = {55},
  pages = {3704 -3716},
  number = {7},
  month = {july },
  doi = {10.1109/TSP.2007.894265},
  file = {Wipf2007.pdf:Wipf2007.pdf:PDF},
  issn = {1053-587X},
  keywords = {automatic relevance determination;coefficient expansions;cost function;empirical
	Bayesian strategy;global minima;local minima;posterior distribution;signal
	vectors;simultaneous sparse approximation problem;source localization;sparse
	Bayesian learning;sparse representation problem;Bayes methods;learning
	(artificial intelligence);maximum likelihood estimation;signal representation;},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Wipf2004,
  author = {David P. Wipf and Rao, B.D.},
  title = {Sparse Bayesian learning for basis selection},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2004},
  volume = {52},
  pages = { 2153 - 2164},
  number = {8},
  month = {aug.},
  abstract = {Sparse Bayesian learning (SBL) and specifically relevance vector machines
	have received much attention in the machine learning literature as
	a means of achieving parsimonious representations in the context
	of regression and classification. The methodology relies on a parameterized
	prior that encourages models with few nonzero weights. In this paper,
	we adapt SBL to the signal processing problem of basis selection
	from overcomplete dictionaries, proving several results about the
	SBL cost function that elucidate its general behavior and provide
	solid theoretical justification for this application. Specifically,
	we have shown that SBL retains a desirable property of the #8467;_0
	-norm diversity measure (i.e., the global minimum is achieved at
	the maximally sparse solution) while often possessing a more limited
	constellation of local minima. We have also demonstrated that the
	local minima that do exist are achieved at sparse solutions. Later,
	we provide a novel interpretation of SBL that gives us valuable insight
	into why it is successful in producing sparse representations. Finally,
	we include simulation studies comparing sparse Bayesian learning
	with basis pursuit and the more recent FOCal Underdetermined System
	Solver (FOCUSS) class of basis selection algorithms. These results
	indicate that our theoretical insights translate directly into improved
	performance.},
  doi = {10.1109/TSP.2004.831016},
  file = {Wipf2004.pdf:Wipf2004.pdf:PDF},
  issn = {1053-587X},
  keywords = { basis pursuit; basis selection algorithms; diversity measures; focal
	undetermined system solver; linear inverse problems; machine learning;
	overcomplete dictionaries; relevance vector machines; signal processing;
	sparse Bayesian learning; Bayes methods; inverse problems; iterative
	methods; learning (artificial intelligence); signal representation;},
  owner = {postgres},
  timestamp = {2012.07.06}
}

@ARTICLE{Wright2009,
  author = {Wright, J. and Yang, A.Y. and Ganesh, A. and Sastry, S.S. and Yi
	Ma},
  title = {Robust Face Recognition via Sparse Representation},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2009},
  volume = {31},
  pages = {210 -227},
  number = {2},
  month = {feb. },
  abstract = {We consider the problem of automatically recognizing human faces from
	frontal views with varying expression and illumination, as well as
	occlusion and disguise. We cast the recognition problem as one of
	classifying among multiple linear regression models and argue that
	new theory from sparse signal representation offers the key to addressing
	this problem. Based on a sparse representation computed by C^1 -minimization,
	we propose a general classification algorithm for (image-based) object
	recognition. This new framework provides new insights into two crucial
	issues in face recognition: feature extraction and robustness to
	occlusion. For feature extraction, we show that if sparsity in the
	recognition problem is properly harnessed, the choice of features
	is no longer critical. What is critical, however, is whether the
	number of features is sufficiently large and whether the sparse representation
	is correctly computed. Unconventional features such as downsampled
	images and random projections perform just as well as conventional
	features such as eigenfaces and Laplacianfaces, as long as the dimension
	of the feature space surpasses certain threshold, predicted by the
	theory of sparse representation. This framework can handle errors
	due to occlusion and corruption uniformly by exploiting the fact
	that these errors are often sparse with respect to the standard (pixel)
	basis. The theory of sparse representation helps predict how much
	occlusion the recognition algorithm can handle and how to choose
	the training images to maximize robustness to occlusion. We conduct
	extensive experiments on publicly available databases to verify the
	efficacy of the proposed algorithm and corroborate the above claims.},
  doi = {10.1109/TPAMI.2008.79},
  file = {Wright2009.pdf:Wright2009.pdf:PDF},
  issn = {0162-8828},
  keywords = {Laplacianfaces;downsampled images;eigenfaces;feature extraction;illumination;image-based
	object recognition;multiple linear regression model;occlusion;random
	projections;robust face recognition;sparse signal representation;face
	recognition;feature extraction;lightning;object recognition;random
	processes;regression analysis;signal representation;Algorithms;Artificial
	Intelligence;Biometry;Cluster Analysis;Face;Humans;Image Enhancement;Image
	Interpretation, Computer-Assisted;Pattern Recognition, Automated;Reproducibility
	of Results;Sensitivity and Specificity;Subtraction Technique;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@MISC{yan2009wavelet,
  author = {Yan, J.},
  title = {Wavelet matrix},
  year = {2009},
  file = {yan2009wavelet.pdf:yan2009wavelet.pdf:PDF}
}

@ARTICLE{Yang2012,
  author = {Zai Yang and Lihua Xie and Cishen Zhang},
  title = {Off-grid Direction of Arrival Estimation Using Sparse Bayesian Inference},
  journal = {Arxiv:1108.5838v3},
  year = {2012},
  volume = {Mar},
  pages = {1--13},
  owner = {postgres},
  timestamp = {2012.06.08}
}

@ARTICLE{yang2012unified,
  author = {Yang, Zai and Xie, Lihua and Zhang, Cishen},
  title = {Unified framework and algorithm for quantized compressed sensing},
  journal = {arXiv preprint arXiv:1203.4870},
  year = {2012}
}

@ARTICLE{You2012,
  author = {Y. You and L. Chen and Y. Gu and W. Feng and H. Dai},
  title = {Retrieval of Sparse Solutions of Multiple-Measurement Vectors via
	Zero-point Attracting Projection},
  journal = {Signal Processing},
  year = {2012},
  volume = {92 (12)},
  pages = {3075--3079},
  file = {You2012.pdf:You2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.15}
}

@ARTICLE{Yu2012,
  author = {Siwei Yu and A. Shaharyar Khwaja and Jianwei Ma},
  title = {Compressed sensing of complex-valued data},
  journal = {Signal Processing},
  year = {2012},
  volume = {92},
  pages = {357--362},
  file = {Yu2012.pdf:Yu2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2013.03.09}
}

@ARTICLE{Yuan2006,
  author = {M. Yuan and Y. Lin},
  title = {Model selection and estimation in regression with grouped variables},
  journal = {J. R. Statist. Soc. B},
  year = {2006},
  volume = {68},
  pages = {49--67},
  file = {Yuan2006.pdf:Yuan2006.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.10.24}
}

@ARTICLE{yuan2011epileptic,
  author = {Yuan, Qi and Zhou, Weidong and Li, Shufang and Cai, Dongmei},
  title = {Epileptic EEG classification based on extreme learning machine and
	nonlinear features},
  journal = {Epilepsy research},
  year = {2011},
  volume = {96},
  pages = {29--38},
  number = {1},
  file = {yuan2011epileptic.pdf:yuan2011epileptic.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Zhang_TBME2012a,
  author = {Zhilin Zhang and Tzyy-Ping Jung and Makeig, S. and Rao, B.D.},
  title = {Compressed Sensing of {EEG} for Wireless Telemonitoring With Low
	Energy Consumption and Inexpensive Hardware},
  journal = {Biomedical Engineering, IEEE Transactions on},
  year = {2013},
  volume = {60},
  pages = {221-224},
  number = {1},
  abstract = {Telemonitoring of electroencephalogram (EEG) through wireless body-area
	networks is an evolving direction in personalized medicine. Among
	various constraints in designing such a system, three important constraints
	are energy consumption, data compression, and device cost. Conventional
	data compression methodologies, although effective in data compression,
	consumes significant energy and cannot reduce device cost. Compressed
	sensing (CS), as an emerging data compression methodology, is promising
	in catering to these constraints. However, EEG is nonsparse in the
	time domain and also nonsparse in transformed domains (such as the
	wavelet domain). Therefore, it is extremely difficult for current
	CS algorithms to recover EEG with the quality that satisfies the
	requirements of clinical diagnosis and engineering applications.
	Recently, block sparse Bayesian learning (BSBL) was proposed as a
	new method to the CS problem. This study introduces the technique
	to the telemonitoring of EEG. Experimental results show that its
	recovery quality is better than state-of-the-art CS algorithms, and
	sufficient for practical use. These results suggest that BSBL is
	very promising for telemonitoring of EEG and other nonsparse physiological
	signals.},
  doi = {10.1109/TBME.2012.2217959},
  file = {Zhang_TBME2012a.pdf:Zhang_TBME2012a.pdf:PDF},
  issn = {0018-9294},
  keywords = {Bayes methods;body area networks;compressed sensing;learning (artificial
	intelligence);medical signal processing;patient monitoring;telemedicine;wireless
	sensor networks;BSBL;EEG compressed sensing;block sparse Bayesian
	learning;data compression methodologies;device cost;electroencephalogram;energy
	consumption;nonsparse physiological signals;nonsparse time domain
	EEG data;nonsparse wavelet domain EEG data;personalized medicine;wireless
	body area networks;wireless telemonitoring;Compressed sensing;Dictionaries;Electroencephalography;Energy
	consumption;Sensors;Sparse matrices;Wavelet transforms;Block sparse
	Bayesian learning (BSBL);compressed sensing (CS);electroencephalogram
	(EEG);healthcare;telemonitoring;wireless body-area network (WBAN)}
}

@ARTICLE{Zhang_TBME2012b,
  author = {ZhiLin Zhang and Tzyy-Ping Jung and Makeig, S. and Rao, B.D.},
  title = {Compressed Sensing for Energy-Efficient Wireless Telemonitoring of
	Noninvasive Fetal {ECG} Via Block Sparse Bayesian Learning},
  journal = {Biomedical Engineering, IEEE Transactions on},
  year = {2013},
  volume = {60},
  pages = {300-309},
  number = {2},
  doi = {10.1109/TBME.2012.2226175},
  file = {Zhang_TBME2012b.pdf:Zhang_TBME2012b.pdf:PDF},
  issn = {0018-9294},
  keywords = {Bayes methods;body area networks;compressed sensing;data compression;electrocardiography;energy
	consumption;independent component analysis;medical signal processing;signal
	denoising;signal reconstruction;telemedicine;CPU;block sparse Bayesian
	learning;current compressed sensing algorithms;data compressing-reconstructing;energy-efficient
	wireless telemonitoring;independent component analysis decomposition;low
	energy consumption;multichannel recordings;noise contamination;noninvasive
	fetal ECG;sparse binary sensing matrix;telemedicine;wavelet algorithms;wireless
	body area network;Correlation;Electrocardiography;Noise;Partitioning
	algorithms;Sensors;Signal processing algorithms;Sparse matrices;Block
	sparse Bayesian learning (BSBL);compressed sensing (CS);fetal ECG
	(FECG);healthcare;independent component analysis (ICA);telemedicine;telemonitoring}
}

@ARTICLE{Zhang2013,
  author = {Zhilin Zhang and Tzyy-Ping Jung and Scott Makeig and Bhaskar D. Rao},
  title = {Spatiotemporal Sparse Bayesian Learning with Applications to Compressed
	Sensing of Multichannel Physiological Signals for Wireless Telemonitoring
	and Brain-Computer Interfaces},
  journal = {(submitted) IEEE Transaction on Biomedical Engineering},
  year = {2013},
  volume = {1},
  pages = {1--12},
  file = {Zhang2013.pdf:Zhang2013.pdf:PDF},
  owner = {liu benyuan},
  timestamp = {2013.03.28}
}

@ARTICLE{Zhang2012a,
  author = {Zhang, Z. and Rao, B.D.},
  title = {Extension of {SBL} Algorithms for the Recovery of Block Sparse Signals
	With Intra-Block Correlation},
  journal = {Signal Processing, IEEE Transactions on},
  year = {2013},
  volume = {61},
  pages = {2009-2015},
  number = {8},
  doi = {10.1109/TSP.2013.2241055},
  file = {Zhang2012a.pdf:Zhang2012a.pdf:PDF},
  issn = {1053-587X},
  keywords = {Bayesian methods;Bismuth;Correlation;Cost function;Partitioning algorithms;Sparse
	matrices;Vectors;Block sparse model;compressed sensing;intra-block
	correlation;sparse Bayesian learning (SBL);sparse signal recovery}
}

@TECHREPORT{Zhang2012,
  author = {Zhilin Zhang and Bhaskar D. Rao},
  title = {Clarify Some Issues on the Sparse Bayesian Learning for Sparse Signal
	Recovery},
  institution = {University of California at San Diego},
  year = {2012},
  file = {Zhang2012.pdf:Zhang2012.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.10}
}

@ARTICLE{Zhang2011,
  author = {Zhilin Zhang and Bhaskar D. Rao},
  title = {Sparse Signal Recovery with Temporally Correlated Source Vectors
	Using Sparse Bayesian Learning},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year = {2011},
  volume = {5},
  pages = {912--926},
  number = {5},
  file = {Zhang2011.pdf:Zhang2011.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.08.10}
}

@MISC{zhou2012malsar,
  author = {Zhou, J. and Chen, J. and Ye, J.},
  title = {MALSAR: Multi-tAsk Learning via StructurAl Regularization},
  year = {2012},
  file = {zhou2012malsar.pdf:zhou2012malsar.pdf:PDF},
  publisher = {Arizona State University}
}

@ARTICLE{Zhou2011,
  author = {Jiayu Zhou and Lei Yuan and Jun Liu and Jieping Ye},
  title = {A Multi-Task Learning Formulation for Predicting Disease Progression},
  journal = {KDD},
  year = {2011},
  volume = {1},
  pages = {1--9},
  file = {Zhou2011.pdf:Zhou2011.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.11.18}
}

@INPROCEEDINGS{zhou2011multi,
  author = {Zhou, J. and Yuan, L. and Liu, J. and Ye, J.},
  title = {A multi-task learning formulation for predicting disease progression},
  booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge
	discovery and data mining},
  year = {2011},
  pages = {814--822},
  organization = {ACM},
  file = {zhou2011multi.pdf:zhou2011multi.pdf:PDF}
}

@INPROCEEDINGS{Ziniel2010,
  author = {Ziniel, J. and Potter, L.C. and Schniter, P.},
  title = {Tracking and smoothing of time-varying sparse signals via approximate
	belief propagation},
  booktitle = {Signals, Systems and Computers (ASILOMAR), 2010 Conference Record
	of the Forty Fourth Asilomar Conference on},
  year = {2010},
  pages = {808 -812},
  month = {nov.},
  abstract = {This paper considers the problem of recovering time-varying sparse
	signals from dramatically undersampled measurements. A probabilistic
	signal model is presented that describes two common traits of time-varying
	sparse signals: a support set that changes slowly over time, and
	amplitudes that evolve smoothly in time. An algorithm for recovering
	signals that exhibit these traits is then described. Built on the
	belief propagation framework, the algorithm leverages recently developed
	approximate message passing techniques to perform rapid and accurate
	estimation. The algorithm is capable of performing both causal tracking
	and non-causal smoothing to enable both online and offline processing
	of sparse time series, with a complexity that is linear in all problem
	dimensions. Simulation results illustrate the performance gains obtained
	through exploiting the temporal correlation of the time series relative
	to independent recoveries.},
  doi = {10.1109/ACSSC.2010.5757677},
  file = {Ziniel2010.pdf:Ziniel2010.pdf:PDF},
  issn = {1058-6393},
  keywords = {belief propagation framework;message passing technique;probabilistic
	signal model;sparse time series;temporal correlation;time series;time-varying
	sparse signal;probability;signal processing;time series;},
  owner = {postgres},
  timestamp = {2012.08.18}
}

@ARTICLE{Zou2006,
  author = {Hui Zou},
  title = {The Adaptive Lasso and its Oracle Properties},
  journal = {Journal of American Statistical Association},
  year = {2006},
  volume = {101(476)},
  pages = {1418--1429},
  file = {Zou2006.pdf:Zou2006.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

@ARTICLE{Zou2007,
  author = {Hui Zou and Trevor Hastie and Robert Tibshirani},
  title = {on the ``Degrees of Freedom'' of the lasso},
  journal = {The annals of statistics},
  year = {2007},
  volume = {35(5)},
  pages = {2173--2192},
  file = {Zou2007.pdf:Zou2007.pdf:PDF},
  owner = {postgres},
  timestamp = {2012.09.24}
}

